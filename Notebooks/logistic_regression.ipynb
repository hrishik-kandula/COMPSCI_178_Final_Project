{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5359700c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import warnings\n",
    "from typing import List, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "\n",
    "!pip3 install -U ucimlrepo\n",
    "from ucimlrepo import fetch_ucirepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12226f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_df(df, name=\"temp\"):\n",
    "    \"\"\"\n",
    "    Saves the given DataFrame to a CSV file named '<name>.csv'\n",
    "    \"\"\"\n",
    "    filename = f\"{name}.csv\"\n",
    "    df.to_csv(filename, index=True)  # set index=False if you don't want to save the index\n",
    "    print(f\"Saved DataFrame to {filename}\")\n",
    "\n",
    "def clean_and_drop(X: pd.DataFrame, missing_threshold: float = 0.10) -> pd.DataFrame:\n",
    "    missing_ratios = X.isnull().mean()\n",
    "    to_drop = missing_ratios[missing_ratios > missing_threshold].index.tolist()\n",
    "    print(f\"Dropping columns due to missing data > {int(missing_threshold * 100)}%: {to_drop}\")\n",
    "    X = X.drop(columns=to_drop)\n",
    "\n",
    "    before = len(X)\n",
    "    X = X.dropna()\n",
    "    after = len(X)\n",
    "    print(f\"Dropped {before - after} rows with any remaining NaNs.\")\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bdf3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "warnings.filterwarnings('ignore')\n",
    "diabetes_df = fetch_ucirepo(id=296)\n",
    "#warnings.resetwarnings()\n",
    "\n",
    "X = diabetes_df.data.features\n",
    "y = diabetes_df.data.targets\n",
    "\n",
    "# Clean and normalize the features\n",
    "X = clean_and_drop(X, missing_threshold=0.05)\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Switch label to binary classification\n",
    "y = y.loc[X.index]\n",
    "y = y.replace({'<30': 1, 'NO': 0, '>30': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c380d1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First split: Train vs (Validation + Test)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=seed)\n",
    "\n",
    "# Second split: Train vs Validation (from the 80%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, stratify=y_temp, random_state=seed)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled   = scaler.transform(X_val)\n",
    "X_test_scaled  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceeae36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(clf, X_val, y_val, model_name=\"Model\"):\n",
    "    y_proba = clf.predict_proba(X_val)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_val, y_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='blue', label=f'AUC = {roc_auc:.2f}')\n",
    "    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'{model_name} ROC Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_learning_curve_errors(clf, X_tr: np.array, y_tr: np.array, \n",
    "                                X_te: np.array, y_te: np.array, \n",
    "                                seed: int, train_sizes: list[int], \n",
    "                                title: str = \"Learning Curve\") -> None:\n",
    "    \n",
    "    tr_err = []\n",
    "    te_err = []\n",
    "\n",
    "    for n_tr in train_sizes:\n",
    "        #print(f\"Training with {n_tr} samples...\")\n",
    "        # Slice the training set\n",
    "        X_subset = X_tr[:n_tr, :]\n",
    "        y_subset = y_tr[:n_tr]\n",
    "\n",
    "        # Clone model to avoid state carryover\n",
    "        model = clone(clf)\n",
    "        model.fit(X_subset, y_subset)\n",
    "\n",
    "        # Compute errors\n",
    "        tr_pred = model.predict(X_subset)\n",
    "        te_pred = model.predict(X_te)\n",
    "        tr_err.append(1.0 - accuracy_score(y_subset, tr_pred))\n",
    "        te_err.append(1.0 - accuracy_score(y_te, te_pred))\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.plot(train_sizes, tr_err, marker='o', label='Training Error')\n",
    "    plt.plot(train_sizes, te_err, marker='s', label='Test Error')\n",
    "    plt.xlabel(\"Training Set Size\")\n",
    "    plt.ylabel(\"Error Rate\")\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84897339",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(max_iter=1000, random_state=seed)\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_val_scaled)\n",
    "\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "plot_roc_curve(clf, X_test_scaled, y_test, model_name=\"Logistic Regression\")\n",
    "\n",
    "train_sizes = [500, 1000, 2000, 5000, 10000, 20000, 30000, 40000, 50000]\n",
    "\n",
    "plot_learning_curve_errors(clf, X_train_scaled, y_train.values.ravel(),\n",
    "                           X_test_scaled, y_test.values.ravel(),\n",
    "                           seed=seed, train_sizes=train_sizes,\n",
    "                           title=\"Learning Curve (Logistic Regression)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8d9d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = SelectKBest(score_func=f_classif, k=20)\n",
    "X_train_selected = selector.fit_transform(X_train_scaled, y_train)\n",
    "X_val_selected = selector.transform(X_val_scaled)\n",
    "X_test_selected = selector.transform(X_test_scaled)\n",
    "\n",
    "tuned_clf = LogisticRegression(max_iter=1000, random_state=seed)\n",
    "tuned_clf.fit(X_train_selected, y_train)\n",
    "\n",
    "y_pred = tuned_clf.predict(X_val_selected)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "plot_roc_curve(tuned_clf, X_test_selected, y_test, model_name=\"Optimized Logistic Regression\")\n",
    "\n",
    "train_sizes = [500, 1000, 2000, 5000, 10000, 20000, 30000, 40000, 50000]\n",
    "\n",
    "plot_learning_curve_errors(tuned_clf, X_train_selected, y_train.values.ravel(),\n",
    "                           X_test_selected, y_test.values.ravel(),\n",
    "                           seed=seed, train_sizes=train_sizes,\n",
    "                           title=\"Learning Curve (Optimized Logistic Regression)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cs178_env)",
   "language": "python",
   "name": "cs178_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
